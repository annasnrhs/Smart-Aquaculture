{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siti Nur Hasanah_G6501211062_fish-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ObpTNvkE-Y7d",
        "EVq852_zyjn2",
        "8ijPHnBUyjoL",
        "9qHMauNCyjoO",
        "EPYLOF62gEkx",
        "G53UEWoHr3H1",
        "fht3SmnZyzl9"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObpTNvkE-Y7d"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EC0xCq7yjnu"
      },
      "source": [
        "!pip install -U keras-tuner # for hyperparameter tuning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UewyuYWWBIrk"
      },
      "source": [
        "# mount to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95pqG36qzCg_"
      },
      "source": [
        "#! pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZgfgXAVpeV2"
      },
      "source": [
        "#mkdir /root/kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mIiAWsz0vQK"
      },
      "source": [
        "# ! cp /content/drive/MyDrive/FISH_CLASSIFICATION/kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOL18LCA09kv"
      },
      "source": [
        "# ! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy0jo2KF1OVH"
      },
      "source": [
        "# ! kaggle datasets download -d crowww/a-large-scale-fish-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVq852_zyjn2"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcx7s6tI1-ag"
      },
      "source": [
        "# unzip dataset\n",
        "'''\n",
        "import zipfile, os\n",
        "\n",
        "local_zip = '/content/a-large-scale-fish-dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/drive/MyDrive/FISH_CLASSIFICATION/dataset')\n",
        "zip_ref.close()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyM2Goekyjn5"
      },
      "source": [
        "# library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.preprocessing.image import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.applications.efficientnet import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-ADW1qqyjn7"
      },
      "source": [
        "img_dir = Path('/content/drive/MyDrive/FISH_CLASSIFICATION/dataset/Fish_Dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_vzv4nRyjn8"
      },
      "source": [
        "filepaths = list(img_dir.glob(r'**/*.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRjACVElyjn9"
      },
      "source": [
        "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
        "\n",
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "img_df = pd.concat([filepaths, labels], axis=1)\n",
        "\n",
        "# drop GT images\n",
        "# GT = ground truth\n",
        "img_df = img_df[img_df['Label'].apply(lambda x: x[-2:] != 'GT')]\n",
        "img_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PYtLPOiyjn_"
      },
      "source": [
        "# get a random sample of items from an axis of object\n",
        "# frac is Fraction of axis items to return.\n",
        "img_df = img_df.sample(frac=1).reset_index(drop=True)\n",
        "img_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_gONGY2yjoD"
      },
      "source": [
        "img_df['Label'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h3UlsCyc7Ju"
      },
      "source": [
        "img_df.Label.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_YD53EKyjoF"
      },
      "source": [
        "# display 10 picture of the dataset with their labels\n",
        "fig, axes = plt.subplots(nrows=2,  ncols=5, figsize=(15,7), subplot_kw={'xticks':[], 'yticks':[]})\n",
        "\n",
        "# Axes.flat means a 1D iterator over the array\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(img_df.Filepath[i]))\n",
        "    ax.set_title(img_df.Label[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARD_TkpH6xsQ"
      },
      "source": [
        "import cv2\n",
        "\n",
        "im = cv2.imread(img_df.Filepath[1])\n",
        "print('shape of img',im.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjpJP3zGyjoI"
      },
      "source": [
        "split data to 80% train, 10% validation, and 10% test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohcfxF0FyjoK"
      },
      "source": [
        "# splitting data to train, validation and test sets\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 1-train_ratio-val_ratio\n",
        "\n",
        "train_df, test_df = train_test_split(img_df, test_size = 1-train_ratio, random_state = 42)\n",
        "val_df, test_df = train_test_split(test_df, test_size = test_ratio/(test_ratio + val_ratio), random_state = 42)\n",
        "\n",
        "print('Total image in data train:', train_df.shape)\n",
        "print('Total image in data validation:', val_df.shape)\n",
        "print('Total image in data test:', test_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ijPHnBUyjoL"
      },
      "source": [
        "# Data augmentation\n",
        "Data augmentation is a technique that used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCKCSFtAyjoM"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "aug_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range  = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split = 0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9tVtRV6yjoN"
      },
      "source": [
        "img_size = (224, 224)\n",
        "\n",
        "train_img = aug_generator.flow_from_dataframe(\n",
        "    dataframe = train_df,\n",
        "    x_col = 'Filepath',\n",
        "    y_col = 'Label',\n",
        "    target_size = img_size,\n",
        "    color_mode = 'rgb',\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = True\n",
        "    )\n",
        "\n",
        "val_img = aug_generator.flow_from_dataframe(\n",
        "    dataframe = val_df,\n",
        "    x_col = 'Filepath',\n",
        "    y_col = 'Label',\n",
        "    target_size = img_size,\n",
        "    color_mode = 'rgb',\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = False\n",
        "    )\n",
        "\n",
        "test_img = aug_generator.flow_from_dataframe(\n",
        "    dataframe = test_df,\n",
        "    x_col = 'Filepath',\n",
        "    y_col = 'Label',\n",
        "    target_size = img_size,\n",
        "    color_mode = 'rgb',\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = False\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQhhO1DFZPJk"
      },
      "source": [
        "print(len(train_img))\n",
        "print(len(val_img))\n",
        "print(len(test_img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm9idic3S9MX"
      },
      "source": [
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "def show_grid(image_list,nrows,ncols,label_list=None,show_labels=False,savename=None,figsize=(10,10),showaxis='off'):\n",
        "    if type(image_list) is not list:\n",
        "        if(image_list.shape[-1]==1):\n",
        "            image_list = [image_list[i,:,:,0] for i in range(image_list.shape[0])]\n",
        "        elif(image_list.shape[-1]==3):\n",
        "            image_list = [image_list[i,:,:,:] for i in range(image_list.shape[0])]\n",
        "    fig = plt.figure(None, figsize,frameon=False)\n",
        "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                     nrows_ncols=(nrows, ncols),  # creates 2x2 grid of axes\n",
        "                     axes_pad=0.3,  # pad between axes in inch.\n",
        "                     share_all=True,\n",
        "                     )\n",
        "    for i in range(nrows*ncols):\n",
        "        ax = grid[i]\n",
        "        ax.imshow(image_list[i],cmap='Greys_r')  # The AxesGrid object work as a list of axes.\n",
        "        ax.axis('off')\n",
        "        if show_labels:\n",
        "            ax.set_title(class_mapping[y_int[i]])\n",
        "    if savename != None:\n",
        "        plt.savefig(savename,bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbfygkwzTVTI"
      },
      "source": [
        "x, y = next(train_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adUsD7ojTDMv"
      },
      "source": [
        "show_grid(x,4,6,label_list=None,show_labels=False,figsize=(20,12))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6twZKVqzqCt"
      },
      "source": [
        "# CNN (no pretrained model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW7voyEJegZQ"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbI1w1-CF4C-"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os, random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "float_formatter = lambda x: '%.4f' % x\n",
        "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
        "np.set_printoptions(threshold=np.inf, suppress=True, precision=4)\n",
        "\n",
        "plt.style.use(\"seaborn-colorblind\")\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
        "sns.set_style(\"darkgrid\")\n",
        "#sns.set_context(\"talk\")\n",
        "sns.set_context(context='notebook', font_scale=1.25)\n",
        "sns.set_style({\"font.sans-serif\": [\"Verdana\", \"Arial\", \"Calibri\", \"DejaVu Sans\"]})\n",
        "\n",
        "# NOTE: It is important that you set a seed value to get same results in every run.\n",
        "# Any number is Ok.\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGSI8eAizt8s"
      },
      "source": [
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.layers import (Input, Dense, Dropout, Conv2D, MaxPooling2D, Activation,\n",
        "                          BatchNormalization, Flatten)\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "\n",
        "K.clear_session()   # start afresh each time!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAv7Ipkq4zVO"
      },
      "source": [
        "def build_model(use_l2_reg=False, use_dropout=False, lr=0.0001,\n",
        "                l2_loss_lambda=0.0015):\n",
        "  K.clear_session()\n",
        "\n",
        "  assert l2_loss_lambda is not None\n",
        "\n",
        "  l2 = regularizers.l2(l2_loss_lambda) if use_l2_reg else None\n",
        "\n",
        "  if l2 is not None: print('Using L2 regularization %.6f' % l2_loss_lambda)\n",
        "\n",
        "  inputs = Input(shape=(224, 224, 3))\n",
        "\n",
        "  x = Conv2D(filters=32, kernel_size=(3, 3), padding='same', kernel_regularizer=l2, activation='relu')(inputs)\n",
        "  x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "  if use_dropout: x = Dropout(0.15)(x)\n",
        "\n",
        "  x = Conv2D(filters=64, kernel_size=(3, 3), padding='same', kernel_regularizer=l2, activation='relu')(x)\n",
        "  x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "  if use_dropout: x = Dropout(0.2)(x)\n",
        "\n",
        "  x = Conv2D(filters=128, kernel_size=(3, 3), padding='same', kernel_regularizer=l2, activation='relu')(x)\n",
        "  x = MaxPool2D(pool_size=(2, 2))(x)\n",
        "  if use_dropout: x = Dropout(0.3)(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  if use_dropout: x = Dropout(0.4)(x)\n",
        "\n",
        "  x = Dense(256, activation='relu', kernel_regularizer=l2)(x)\n",
        "  if use_dropout: x = Dropout(0.4)(x)\n",
        "  x = Dense(512, activation='relu', kernel_regularizer=l2)(x)\n",
        "  if use_dropout: x = Dropout(0.2)(x)\n",
        "\n",
        "  outputs = Dense(9, activation='softmax')(x)\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIrwIyPyEXV2"
      },
      "source": [
        "checkpoint_path = '/content/drive/MyDrive/FISH_CLASSIFICATION/my_model/basemodel.h5'\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=5, min_lr=0.000001, verbose=1),\n",
        "    ModelCheckpoint(monitor='val_loss', mode='min', filepath=checkpoint_path, verbose=1, save_best_only=True, save_weights_only=False)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvGfn4AV9B_3"
      },
      "source": [
        "## Base model\n",
        "a model with no regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H159aBN_LT91"
      },
      "source": [
        "### Pre-tuned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjDSiJS6lNXy"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "#create model\n",
        "model = Sequential()\n",
        "#add model layers\n",
        "model.add(Conv2D(32, padding='same', kernel_size=3, activation='relu', input_shape=(224,224,3)))\n",
        "model.add(MaxPool2D(2,2))\n",
        "model.add(Conv2D(64, padding='same', kernel_size=3, activation='relu', input_shape=(224,224,3)))\n",
        "model.add(MaxPool2D(2,2))\n",
        "model.add(Conv2D(128, padding='same', kernel_size=3, activation='relu', input_shape=(224,224,3)))\n",
        "model.add(MaxPool2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(9, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPH7iZRT8qXO"
      },
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyIBb6Nz9PnF"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='basemodel.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9fChv9P8t7m"
      },
      "source": [
        "history = model.fit(\n",
        "    train_img,\n",
        "    validation_data=val_img,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNKT0DU1SDrt"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mJ9keP9Unyg"
      },
      "source": [
        "load_model = keras.models.load_model('/content/drive/MyDrive/FISH_CLASSIFICATION/my_model/MyModel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vguvQk4uU4qT"
      },
      "source": [
        "load_model.evaluate(test_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ7QAmzxU-dO"
      },
      "source": [
        "labels = list(test_img.class_indices.keys())   \n",
        "y_true = test_img.classes\n",
        "y_pred = load_model.predict_generator(test_img)\n",
        "rounded_pred = np.argmax(y_pred, axis=1)\n",
        "cm = confusion_matrix(y_true=y_true, y_pred=rounded_pred)\n",
        "plot_confusion_matrix(cm, labels, title=\"ResNet Pretuned\")\n",
        "report = classification_report(y_true, rounded_pred, target_names=labels)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOxCOaqwWjmr"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='resnet_pretuned.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}